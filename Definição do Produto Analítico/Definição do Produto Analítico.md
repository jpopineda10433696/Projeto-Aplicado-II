# DefiniÃ§Ã£o da linguagem de programaÃ§Ã£o
A principal linguagem de programaÃ§Ã£o a ser utilizada serÃ¡ a linguagem Python, devido ao alto suporte de bibliotecas de anÃ¡lise de dados, modelagem de NLP (Processamento de Linguagem Natural).
As bibliotecas utilizadas, com suas respectivas justificativas sÃ£o as seguintes:

- **Pandas**: ManipulaÃ§Ã£o e anÃ¡lise de dados.
- **NumPy**: OperaÃ§Ãµes matemÃ¡ticas e manipulaÃ§Ã£o de arrays.
- **Matplotlib/Seaborn**: VisualizaÃ§Ã£o de dados.
- **NLTK (Natural Language Toolkit)**: Processamento de linguagem natural (tokenizaÃ§Ã£o, remoÃ§Ã£o de stopwords, etc.).
- **Unicodedata**: NormalizaÃ§Ã£o de textos com base no cÃ³digo ASCII.
- **WordCloud**: GeraÃ§Ã£o de nuvens de palavras.
- **Scikit-learn**: Algoritmos de aprendizado de mÃ¡quina e mÃ©tricas de avaliaÃ§Ã£o.
- **TextBlob**: AnÃ¡lise de sentimento.


# AnÃ¡lise exploratÃ³ria da base de dados

A anÃ¡lise exploratÃ³ria inicial realizada busca trazer informaÃ§Ãµes sobre as estruturas dos dados, identificar padrÃµes, valores ausentes e distribuiÃ§Ã£o dos tweets. 
Devido a recentes restriÃ§Ãµes na API da rede social X para extraÃ§Ã£o dos tweets, somado com mudanÃ§as nos termos de uso da plataforma que impedem extraÃ§Ã£o direta dos dados via HTML com as principais bibliotecas python (Snscrape, BeautifulSoup etc.), os tweets mais recentes foram extraÃ­dos manualmente.
Para fins de rotulagem dos dados para garantir mÃ©tricas que garantam a acuracidade do modelo, foi criada uma coluna na base de dados nomeada de sentimentos, onde o grupo classificou os tweets em trÃªs parÃ¢metros:

  -  *1* : Sentimento Positivo
  -  *0* : Sentimento Neutro - Sem crÃ­ticas ou elogios
  - *-1*: Sentimento Negativo
    
O dataframe foi criado via biblioteca pandas e abaixo estÃ£o as principais caracterÃ­sticas obtidas.

- **CabeÃ§alho**

	O dataset Ã© composto por 5 colunas, que representam caracterÃ­sticas do tweet, como data de publicaÃ§Ã£o, link para acesso, usuÃ¡rio, conteÃºdo e rÃ³tulo de sentimento, conforme mencionado anteriormente.

  ![image](https://github.com/user-attachments/assets/3424e88d-a472-46be-8db3-f5b955b6d8c8)



- **Tipos de dados**

	Os tipos de dados sÃ£o, em sua maior parte, do tipo â€œobjectâ€ devido a alta variaÃ§Ã£o do tipo de conteÃºdo de cada atributo. JÃ¡ a coluna â€œsentimentoâ€ Ã© do tipo â€œint64â€ pois os rÃ³tulos de sentimento foram escolhidos com base em nÃºmeros inteiros (-1,0,1).
	
	![image](https://github.com/user-attachments/assets/7aebadcb-cc7e-47ab-88f2-2a95407a653c)


- **DistribuiÃ§Ã£o dos sentimentos (rÃ³tulos)**

  De acordo com a distribuiÃ§Ã£o abaixo sobre os sentimentos, Ã© possÃ­vel verificar que cerca de 68 dos 100 tweets sÃ£o negativos em relaÃ§Ã£o Ã  situaÃ§Ã£o da saÃºde no Brasil (aproximadamente 68% do total).
  Em relaÃ§Ã£o aos sentimentos negativos ou neutros, nÃ£o existe nenhuma variaÃ§Ã£o perceptÃ­vel dentro da amostra de tweets mais recentes.

	![image](https://github.com/user-attachments/assets/5ca3028a-30dd-4eb6-b6eb-0f1a5f3ce605)


  
- **Nuvem de palavras**

  Ã‰ possÃ­vel verificar que, sem um tratamento adequado da base de dados, nÃ£o Ã© possÃ­vel distinguir termos relacionados Ã  classificaÃ§Ã£o de sentimentos dentro da nuvem de palavras, pois as mesmas trazem uma densidade maior de termos com maior repetiÃ§Ã£o, em sua maioria artigos, preposiÃ§Ãµes e conjunÃ§Ãµes (ou stopwords, conceito que serÃ¡ explorado na prÃ³xima etapa).

  ![image](https://github.com/user-attachments/assets/4e37ab67-12e7-41ae-a026-7c19849ce3b5)



# Tratamento da base de dados

Devido a complexidade da manipulaÃ§Ã£o de linguagem natural, o tratamento da base de dados foi realizado em vÃ¡rias etapas, sendo elas:

- **RemoÃ§Ã£o de links, menÃ§Ãµes e caracteres especiais.**
  
  Para isso, foi utilizada a biblioteca â€œreâ€ que realiza manipulaÃ§Ã£o de textos retirando caracteres especiais, alÃ©m da â€œunicodedataâ€ que foi utilizada para normalizar os tweets e remover acentos.

      def limpar_texto(texto):
          texto = re.sub(r"http\S+|www\S+|https\S+", '', texto, flags=re.MULTILINE)
          texto = re.sub(r'\@\w+|\#', '', texto)
          texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')
          texto = re.sub(r'[^A-Za-z0-9\s]', '', texto)
          texto = texto.lower()
          return texto

- **RemoÃ§Ã£o de stopwords**
  
  Para a remoÃ§Ã£o de stopwords, ou seja, caracteres irrelevantes para a anÃ¡lise textual, foi utilizada a biblioteca â€œnltkâ€.

      stop_words = set(stopwords.words('portuguese'))
      df['texto_limpo'] = df['texto_limpo'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in stop_words]))

Por fim, com a aplicaÃ§Ã£o das funÃ§Ãµes acima de tratamento do dataset e realizando um filtro de palavras-chave que foram utilizados para pesquisa do tweet, obtemos a nova nuvem de palavras abaixo.

![image](https://github.com/user-attachments/assets/944e07b1-7e22-4238-8550-84ca6f15ce4c)



Ã‰ possÃ­vel perceber que as palavras maiores como â€œfilaâ€, â€œatendimentoâ€, â€œfaltaâ€, â€œpÃ©ssimoâ€, â€œhorrÃ­velâ€ e â€œproblemaâ€ (e derivados), corrobora a distribuiÃ§Ã£o anterior dos rÃ³tulos de dados de que grande parte dos tweets se refere a fatores negativos ou reclamaÃ§Ãµes especÃ­ficas sobre o sistema pÃºblico de saÃºde no Brasil.

Nas prÃ³ximas etapas, serÃ£o construÃ­dos algoritmos de aprendizado de mÃ¡quina para criar um modelo que realizarÃ¡ a anÃ¡lise dessas principais palavras e irÃ¡ atribuir rÃ³tulos de classificaÃ§Ã£o de sentimento para identificar a acurÃ¡cia do modelo em relaÃ§Ã£o Ã  rotulagem atribuÃ­da pelo grupo.

O cÃ³digo detalhado estÃ¡ disponÃ­vel no projeto do GitHub na pasta â€œDefiniÃ§Ã£o do Produto AnalÃ­ticoâ€.

# DefiniÃ§Ã£o e descriÃ§Ã£o das bases teÃ³ricas dos mÃ©todos

A construÃ§Ã£o do modelo de classificaÃ§Ã£o de sentimentos utilizarÃ¡ os conceitos teÃ³ricos mais relevantes com base nos projetos existentes desse tipo de abordagem.
Dentre as principais base teÃ³ricas estudadas no curso e suas definiÃ§Ãµes estÃ£o:

  - **Processamento de Linguagem Natural (NLP)**: UtilizaÃ§Ã£o de linguagem computacional para compreender e gerar linguagem humana de forma efetiva e coesa.
As principais aplicaÃ§Ãµes no projeto de NLP sÃ£o a identificaÃ§Ã£o de caracteres especiais, manipulaÃ§Ã£o de stopwords, normalizaÃ§Ã£o de palavras e identificaÃ§Ã£o de padrÃµes linguÃ­sticos para classificaÃ§Ã£o de sentimento.

  - **Aprendizado de MÃ¡quina**: Descoberta de padrÃµes via algoritmos computacionais para realizar previsÃµes ou classificaÃ§Ãµes.
Nas prÃ³ximas etapas, serÃ¡ utilizada a biblioteca â€œsklearnâ€ para criaÃ§Ã£o de algoritmos de classificaÃ§Ã£o, regressÃ£o logÃ­stica e criaÃ§Ã£o de mÃ©tricas de desempenho.

  - **AquisiÃ§Ã£o e PreparaÃ§Ã£o de Dados (ETL)**: ExtraÃ§Ã£o, TransformaÃ§Ã£o, Limpeza e Carga de dados para os modelos de aprendizado de mÃ¡quina.
No item anterior, foi realizado o carregamento das bases de dados para o Google Colab e posterior transformaÃ§Ã£o dos dados com pandas para manipular o dataset, retirar termos indesejados, calcular as principais estatÃ­sticas, etc.


# DefiniÃ§Ã£o e descriÃ§Ã£o de como serÃ¡ calculada a acurÃ¡cia
	
A escolha das mÃ©tricas a serem utilizadas Ã© de extrema importÃ¢ncia pois definem se o nosso modelo de anÃ¡lise de sentimentos Ã© suficiente para prever outros casos com acuracidade, entender (em tempo real) qual Ã© o sentimento do brasileiro em relaÃ§Ã£o Ã  saÃºde pÃºblica do paÃ­s sem vieses e tambÃ©m garantir com que o modelo se assemelha Ã  visÃ£o humana sobre o sentimento de outros indivÃ­duos com assertividade.
Para essa garantia, utilizaremos as seguintes mÃ©tricas de avaliaÃ§Ã£o:

 - **AcurÃ¡cia**:

       AcurÃ¡cia = PrevisÃµes Corretas/Total de PrevisÃµes

   A definiÃ§Ã£o de â€œPrevisÃµes Corretasâ€ serÃ¡ garantida pela comparaÃ§Ã£o entre o sentimento do tweet identificado pelo modelo e o rotulado pelo grupo.

  - **Matriz de ConfusÃ£o**:

    |                   | Previsto Positivo | Previsto Negativo |
    |-------------------|-------------------|-------------------|
    | **Real Positivo** | VP                | FN                |
    | **Real Negativo** | FP                | VN                |


    A matriz de confusÃ£o compara as frequÃªncias de classificaÃ§Ã£o para cada classe do modelo, ou seja, mostrando as classificaÃ§Ãµes corretas e incorretas para cada classe. Esse tipo de mÃ©trica Ã© importante pois permite identificar onde exatamente estÃ¡ a maior taxa de erro do modelo.

  - **RelatÃ³rio de ClassificaÃ§Ã£o**
    
	Ã‰ uma mÃ©trica de desempenho do modelo realizando a divisÃ£o do mesmo em classes. Esse relatÃ³rio Ã© dividido nas seguinte mÃ©tricas principais:

	**1. Precision**

		ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› = ğ‘‰ğ‘’ğ‘Ÿğ‘‘ğ‘ğ‘‘ğ‘’ğ‘–ğ‘Ÿğ‘œğ‘  ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘œğ‘ /(ğ‘‰ğ‘’ğ‘Ÿğ‘‘ğ‘ğ‘‘ğ‘’ğ‘–ğ‘Ÿğ‘œğ‘  ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘œğ‘  + ğ¹ğ‘ğ‘™ğ‘ ğ‘œğ‘  ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘œğ‘ )

	Ou seja, mede do total de previsÃµes positivas, quantas estÃ£o corretas.

	**2. Recall**

		ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ = ğ‘‰ğ‘’ğ‘Ÿğ‘‘ğ‘ğ‘‘ğ‘’ğ‘–ğ‘Ÿğ‘œğ‘  ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘œğ‘ /(ğ‘‰ğ‘’ğ‘Ÿğ‘‘ğ‘ğ‘‘ğ‘’ğ‘–ğ‘Ÿğ‘œğ‘  ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘œğ‘  + ğ¹ğ‘ğ‘™ğ‘ ğ‘œğ‘  ğ‘ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘œğ‘ )

	Do total de casos realmente positivos, quantos foram identificados.

	**3. F1-Score**

		ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› = 2 * (ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› * ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™)/(ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› + ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™)

	MÃ©dia harmÃ´nica entre Precision e Recall, avaliando o equilÃ­brio entre essas
	duas mÃ©tricas.

	**4. Support**

	NÃºmero de ocorrÃªncias de cada classe no conjunto de dados.
